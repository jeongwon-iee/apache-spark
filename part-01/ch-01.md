# Part 1. 빅데이터와 스파크 간단히 살펴보기

### 목차

- Chapter 1. 아파치 스파크란
  - 1.1 아파치 스파크의 철학
  - 1.2 스파크의 등장 배경
  - 1.3 스파크의 역사
  - 1.4 스파크의 현재와 미래
  - 1.5 스파크 실행하기
  - 1.6 정리

&nbsp;

## Chapter 1. 아파치 스파크란

아파치 스파크는 병렬 처리 오픈소스 엔진이며, 클러스터 환경에서 데이터를 병렬로 처리하는 라이브러리 집합  
널리 쓰이는 네 가지 언어(파이썬, 자바, 스칼라, R)를 지원, SQL 뿐만 아니라 스트리밍, 머신러닝에 이르기까지 넓은 범위의 라이브러리를 제공  
스파크는 단일 노트북 환경에서부터 수천 대의 서버로 구성된 클러스터까지 다양한 환경에서 실행 가능  

이러한 특성으로 빅데이터 처리를 쉽게 할 수 있으며, 엄청난 규모의 클러스터로 확장해나갈 수 있다.

&nbsp;

### 1.1 아파치 스파크의 철학

> 빅데이터를 위한 **통합** **컴퓨팅 엔진**과 **라이브러리** 집합

#### 통합

스파크가 발표되기 전에는 통합 엔진을 제공하는 병렬 데이터 처리용 오픈소스가 없었다.  
따라서 사용자는 다양한 API와 시스템을 직접 조합해 애플리케이션을 작성해야 했다.

스파크는 간단한 데이터 읽기에서부터 SQL 처리, 머신러닝 그리고 스트림 처리에 이르기까지  
다양한 데이터 분석 작업을 **같은 연산 엔진과 일관성 있는 API로 수행**할 수 있도록 설계 되어 있다.  

스파크 API는 사용자 애플리케이션에서 다른 라이브러리의 기능을 조합해 더 나은 성능을 발휘할 수 있도록 설계 되었다.
- 스파크는 일관성 있는 조합형 API를 제공하여, 작은 코드 조각이나 기존 라이브러리를 사용해 애플리케이션을 만들 수 있다.  
- 조합형 API만으로 문제를 해결할 수 없을 때는 직접 스파크 기반의 라이브러리를 만들 수도 있다.  
ex. SQL 쿼리로 데이터를 읽고 ML 라이브러리로 머신러닝 모델을 평가해야 할 경우, 스파크 엔진을 사용하면 이 두 단계를 하나로 병합하고 데이터를 한 번만 조회할 수 있다.

#### 컴퓨팅 엔진

스파크는 "통합"이라는 관점을 중시하면서 기능의 범위를 컴퓨팅 엔진으로 제한.  
스파크는 내부에 데이터를 오랜 시간 저장하지 않으며 특정 저장소 시스템을 선호하지도 않는다.  
데이터의 이동은 높은 비용을 유발하기에, 스파크는 **데이터 저장 위치에 상관없이 처리에 집중**하도록 만들어졌다.

스파크는 저장소 시스템의 데이터를 연산하는 역할만 수행할 뿐 영구 저장소 역할은 수행하지 않는다.  
대신, 클라우드 기반의 저장소 Azure Storage, Amazon S3, 분산 파일 시스템인 Apache Hadoop, 키/값 저장소인 Apache Cassandra, 메시지 전달 서비스인 Apache Kafka 등의 저장소를 지원  

*Apache Hadoop과의 차이*  
스파크는 연산 기능에 초점을 맞추면서 아파치 하둡 같은 기존 빅데이터 플랫폼과 차별화  
하둡은 범용 서버 클러스터 환경에서 저비용 저장 장치를 사용하도록 설계된 하둡 파일 시스템(저장소)과 맵리듀스(컴퓨팅 시스템)을 가지고 있으며, 두 시스템은 매우 밀접히 연관된다.  
이와 같은 구조(하둡)에서는 둘 중 하나의 시스템만 단독으로 사용하기 어렵다.  
특히 다른 저장소의 데이터에 접근하는 애플리케이션을 개발하기 어렵다.  

#### 라이브러리

스파크 컴포넌트는 데이터 분석 작업에 필요한 통합 API를 제공하는 **통합 엔진 기반의 자체 라이브러리**

스파크의 표준 라이브러리는 여러 오픈소스 프로젝트의 집합체  
외부 라이브러리 목록은 [spark-packages.org](https://spark-packages.org/)에서 확인할 수 있다.

&nbsp;

### 1.2 스파크의 등장 배경

#### 더 많은 연산과 대규모 데이터 처리를 프로세서의 성능 향상에 맡겼던 과거

역사적으로 컴퓨터는 프로세서의 성능 향상에 힘입어 해마다 빨라졌다. (매년 새롭게 출시되는 프로세서들은 이전 버전보다 더 많은 양의 명령어를 처리)  
그 결과 애플리케이션은 코드를 수정하지 않아도 자연스럽게 더 빨라졌다.  
대규모 애플리케이션은 이런 경향에 맞춰 만들어졌으며, 대부분의 시스템은 단일 프로세서에서만 실행되도록 설계되었다.

#### 멈춰버린 하드웨어 성능 향상

하드웨어의 성능 향상은 2005년 경에 멈췄다.  
하드웨어 개발자들은 단일 프로세서의 성능 향상 대신 모든 코어가 같은 속도로 동작하는 병렬 CPU 코어를 더 많이 추가하는 방향으로 선회한 것이다.  
이런 현상은 애플리케이션의 성능 향상을 위해 병렬 처리가 필요하며 스파크와 같은 새로운 프로그래밍 모델의 도래를 암시

#### 거대해진 데이터

프로세서의 속도는 개선되지 않았지만, 데이터 수집 비용은 극히 저렴해지고, 데이터는 클러스터에서 처리해야 할 만큼 거대해졌다.  

→ 새로운 프로그래밍 모델이 필요, 이런 문제를 해결하기 위해 아파치 스파크가 탄생했다.

&nbsp;

### 1.3 스파크의 역사

#### 맵리듀스 엔진을 사용하는 대규모 애플리케이션의 난이도와 효율성 문제  

전통적인 머신러닝 알고리즘은 데이터를 10~20회 가량 처리하는데,  
이를 맵리듀스로 처리하려면, 단계별로 맵리듀스 잡을 개발하고, 클러스터에서 각각 실행해야 하므로 매번 데이터를 처음부터 일거야 했다.

#### 스파크의 해결

- 스파크팀은 먼저 여러 단계로 이루어진 애플리케이션을 간결하게 개발할 수 있는 **함수형 프로그래밍 기반의 API**를 설계  
- 연산 단계 사이에서 메모리에 저장된 데이터를 효율적으로 공유할 수 있는 새로운 엔진 기반의 API를 구현

#### 스파크의 진화

- 1.0 이전의 스파크 초기 버전: 함수형 연산
  - **함수형 연산**(자바 객체로 이루어진 컬렉션에 맵이나 리듀스 같은 병렬 연산을 수행하는 방식) 관점에서 API를 정의
- 1.0 이상의 스파크 버전: 스파크 SQL
  - **구조화된 데이터**를 기반으로 동작하는 스파크 SQL 추가
  - 고정형 데이터 포맷을 사용하는 스파크 테이블은 자바의 인메모리 데이터 표현 방식에 종속X
  - 스파크 SQL은 데이터 포맷과 코드를 잘 이해하는 라이브러리와 API를 이용해 강력한 최적화 기능을 제공
- 2.0 이상의 스파크 버전: DataFrame, 머신러닝 파이프라인, 구조적 스트리밍
  - DataFrame, 머신러닝 파이프라인, 자동 최적화를 수행하는 구조적 스트리밍 등 더 강력한 구조체 기반의 신규 API 추가

&nbsp;

### 1.4 스파크의 현재와 미래

스파크 생태계의 여러 신규 프로젝트는 스파크의 영역을 꾸준히 넓혀나가고 있다.  
ex. 고수준 스트리밍 엔진인 구조적 스트리밍은 우버, 넷플릭스, NASA, CERN 과 같은 연구소에서 거대한 규모의 데이터셋을 처리하기 위해 사용

&nbsp;

### 1.5 스파크 실행하기

